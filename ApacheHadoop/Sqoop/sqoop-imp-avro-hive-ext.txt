================= sqoop import as avro hdfs file================================

sqoop import --connect jdbc:oracle:thin:@//host:port/xyz_etl --username abc --password xyz --table BONUS.TRADES --as-avrodatafile --null-non-string 123 -m 8 --target-dir /data/FLZ/import/sqoop/LREG/xyz6

================ Exported avro file in HDFS ====================================

$ hadoop fs -ls /data/FLZ/import/sqoop/LREG/xyz6
Found 9 items
-rw-r--r--   2 splice supergroup           0 2018-03-29 07:53 /data/FLZ/import/sqoop/LREG/xyz6/_SUCCESS
-rw-r--r--   2 splice supergroup       57305 2018-03-29 07:25 /data/FLZ/import/sqoop/LREG/xyz6/part-m-00000.avro
-rw-r--r--   2 splice supergroup      129207 2018-03-29 07:25 /data/FLZ/import/sqoop/LREG/xyz6/part-m-00001.avro
-rw-r--r--   2 splice supergroup      154810 2018-03-29 07:25 /data/FLZ/import/sqoop/LREG/xyz6/part-m-00002.avro
-rw-r--r--   2 splice supergroup      351415 2018-03-29 07:25 /data/FLZ/import/sqoop/LREG/xyz6/part-m-00003.avro
-rw-r--r--   2 splice supergroup     6416082 2018-03-29 07:25 /data/FLZ/import/sqoop/LREG/xyz6/part-m-00004.avro
-rw-r--r--   2 splice supergroup        7270 2018-03-29 07:25 /data/FLZ/import/sqoop/LREG/xyz6/part-m-00005.avro
-rw-r--r--   2 splice supergroup  8879404509 2018-03-29 07:50 /data/FLZ/import/sqoop/LREG/xyz6/part-m-00006.avro
-rw-r--r--   2 splice supergroup 10298185672 2018-03-29 07:53 /data/FLZ/import/sqoop/LREG/xyz6/part-m-00007.avro

================= Now as avro file contains schema in header =====================

STEP 1. Copy any partition to local

        $ hadoop fs -get /data/FLZ/import/sqoop/LREG/xyz6/part-m-00000.avro ./
        
STEP 2. Extract schema from the data file

        $ java -jar /opt/cloudera/parcels/CDH-5.12.0-1.cdh5.12.0.p0.29/jars/avro-tools-1.7.6-cdh5.12.0.jar getschema /home/splice/cetera/part-m-00000.avro > ./part-m-00000.avsc

   NOTE: we can find avro tools jar on cloudera with below command
         $ find / -type f -iname "avro-tools-*.jar"
          /opt/cloudera/parcels/CDH-5.12.0-1.cdh5.12.0.p0.29/jars/avro-tools-1.7.6-cdh5.12.0.jar
          
STEP 3. Now we have schema file generated from STEP 2. Move it to some HDFS location

        $ sudo -su hdfs hadoop fs -put part-m-00000.avsc /user/kumarsu/
        
STEP 4. Now create external table using avro file location and schema.

        CREATE EXTERNAL TABLE BNS.EXT_TRADES
        STORED AS AVRO
        LOCATION '/data/FLZ/import/sqoop/LREG/xyz6/'
        TBLPROPERTIES ('avro.schema.url'='/user/kumarsu/part-m-00000.avsc')
        
        
STEP 5. We can check formatted description of the table.

# Detailed Table Information
Database:               bonus
Owner:                  splice
CreateTime:             Thu Mar 29 11:07:02 EDT 2018
LastAccessTime:         UNKNOWN
Protect Mode:           None
Retention:              0
Location:               hdfs://dhnnlnl001.one.ad:8020/data/FLZ/import/sqoop/LREG/xyz6
Table Type:             EXTERNAL_TABLE
Table Parameters:
        COLUMN_STATS_ACCURATE   false
        EXTERNAL                TRUE
        avro.schema.url         /user/kumarsu/part-m-00000.avsc
        numFiles                0
        numRows                 -1
        rawDataSize             -1
        totalSize               0
        transient_lastDdlTime   1522336022

# Storage Information
SerDe Library:          org.apache.hadoop.hive.serde2.avro.AvroSerDe
InputFormat:            org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat
OutputFormat:           org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat
Compressed:             No
Num Buckets:            -1
Bucket Columns:         []
Sort Columns:           []
Storage Desc Params:
        serialization.format    1
Time taken: 0.252 seconds, Fetched: 99 row(s)

======================================= Important URLs related to Sqoop avro import =============================

http://www.geoinsyssoft.com/avro-file-format/
https://stackoverflow.com/questions/43573421/handling-dates-in-hadoop

